{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "name": "Linear_Regression_and_K_Nearest_Neighbors_Exercises-ANSWERS",
    "notebookId": 2125319687183902,
    "colab": {
      "name": "Regressao.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Uj9oEUvXnWS"
      },
      "source": [
        "# Regressão com Redes Neurais\n",
        "\n",
        "Esse Jupyter é uma adaptação de https://scikit-learn.org/stable/auto_examples/compose/plot_transformed_target.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFyv4vnoXnWY"
      },
      "source": [
        "## Introdução\n",
        "\n",
        "\n",
        "Qua a diferença entre um problema de Classificação e Regressão?\n",
        "\n",
        "\"O problema de classificação ocorre quando a variável alvo possui valores categóricos. Por outro lado, a regressão ocorre quando a variável alvo é contínua.\" Source: https://www.researchgate.net/publication/352749819_Ciencia_dos_Dados_pelo_Processo_de_KDD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbmSuYWeXnWZ"
      },
      "source": [
        "## Gerandando a base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0F8LelBXnWa"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "import numpy as np\n",
        "\n",
        "X, y = make_regression(n_samples=10000, noise=100, random_state=0)\n",
        "\n",
        "y = np.expm1((y + abs(y.min())) / 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUhiYT0IXnWb"
      },
      "source": [
        "## Treinando ANN no Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2dcRjSZbcLv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts5gEV9deBR_"
      },
      "source": [
        "# Normalizar\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry3xm4iPeX7z"
      },
      "source": [
        "from keras.models  import Sequential\n",
        "from keras.layers import InputLayer, Dense\n",
        "from keras.optimizers import adam_v2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDYAnRH_ejs5"
      },
      "source": [
        "# Criar o modelo\n",
        "\n",
        "input_neuron, hidden_neuron, output_neuron = 100, 3, 1\n",
        "\n",
        "mlp = Sequential([                  \n",
        "    InputLayer(input_neuron),\n",
        "    Dense(hidden_neuron, activation=\"relu\"),\n",
        "    Dense(output_neuron)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP477SClezK_"
      },
      "source": [
        "# Usar a função summary()\n",
        "mlp.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8SC9MFze6mF"
      },
      "source": [
        "# Compile o modelo\n",
        "mlp.compile(optimizer=\"adam\", loss=\"mse\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utdvJt0jfGqH"
      },
      "source": [
        "# Treine o modelo\n",
        "batch_size = 16\n",
        "Log = mlp.fit(X_train, y_train, batch_size=batch_size, epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g11kj7BVXnWg"
      },
      "source": [
        "## Medidas Desempenho\n",
        "\n",
        "* **r2_score**(y_test, y_pred)\n",
        "\n",
        "* **median_absolute_error**(y_test, y_pred)\n",
        "\n",
        "* **Gráfico de Dispersão**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BgilJFsXnWh"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "mae = median_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Plot results\n",
        "ax0 = plt.axes()\n",
        "\n",
        "ax0.scatter(y_test, y_pred)\n",
        "ax0.plot([0, 2000], [0, 2000], '--k')\n",
        "ax0.set_ylabel('Target predicted')\n",
        "ax0.set_xlabel('True Target')\n",
        "ax0.set_title('Sem transformação logarítmica do alvo')\n",
        "ax0.text(100, 1750, r'$R^2$=%.2f, MAE=%.2f' % (\n",
        "    r2, mae))\n",
        "ax0.set_xlim([0, 2000])\n",
        "ax0.set_ylim([0, 2000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e3R7FBKXnWh"
      },
      "source": [
        "## Importância do log\n",
        "\n",
        "A função logarítmica é usada para linearizar os alvos, permitindo uma melhor previsão. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oClO4maRc8Fh"
      },
      "source": [
        "y_trans = np.log1p(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShSWYjoiXnWc"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, (ax0, ax1) = plt.subplots(1, 2)\n",
        "\n",
        "ax0.hist(y, bins=100, density=True)\n",
        "ax0.set_xlim([0, 2000])\n",
        "ax0.set_ylabel('Probability')\n",
        "ax0.set_xlabel('Target')\n",
        "ax0.set_title('Target distribution')\n",
        "\n",
        "ax1.hist(y_trans, bins=100, density=True)\n",
        "ax1.set_ylabel('Probability')\n",
        "ax1.set_xlabel('Target')\n",
        "ax1.set_title('Transformed target distribution')\n",
        "\n",
        "f.suptitle(\"Synthetic data\", y=0.06, x=0.53)\n",
        "f.tight_layout(rect=[0.05, 0.05, 0.95, 0.95])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lZaGXFBZORa"
      },
      "source": [
        "# Treinando com o Log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8IWqXt_byHI"
      },
      "source": [
        "y_train = np.log1p(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vb3zIHkjSF8"
      },
      "source": [
        "Log = mlp.fit(X_train, y_train, batch_size=batch_size, epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI0LDeuhjmRL"
      },
      "source": [
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "\n",
        "y_pred = np.expm1(mlp.predict(X_test))\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "mae = median_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Plot results\n",
        "ax0 = plt.axes()\n",
        "\n",
        "ax0.scatter(y_test, y_pred)\n",
        "ax0.plot([0, 2000], [0, 2000], '--k')\n",
        "ax0.set_ylabel('Target predicted')\n",
        "ax0.set_xlabel('True Target')\n",
        "ax0.set_title('Sem transformação logarítmica do alvo')\n",
        "ax0.text(100, 1750, r'$R^2$=%.2f, MAE=%.2f' % (\n",
        "    r2, mae))\n",
        "ax0.set_xlim([0, 2000])\n",
        "ax0.set_ylim([0, 2000])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}