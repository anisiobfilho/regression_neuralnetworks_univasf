{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "RegressionByNeuralNetwork.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8df741e"
      },
      "source": [
        "<br>\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/elaynelemos/prediction-of-orders-dmc/main/assets/img/univasf-logo.png\" width=200>\n",
        "<h3>\n",
        "    UNIVERSIDADE FEDERAL DO VALE DO SÃO FRANCISCO\n",
        "    <br>COLEGIADO DE ENGENHARIA DE COMPUTAÇÃO\n",
        "</h3>\n",
        "\n",
        "<h3>Orientador</h3>\n",
        "<span>Prof. Dr. Rosalvo Ferreira de Oliveira Neto</span>\n",
        "\n",
        "<h3>Discentes</h3>\n",
        "<span>Anísio Pereira Batista Filho\n",
        "<br>Edjair Aguiar Gomes Filho\n",
        "<br>Elayne Rute Lessa Lemos</span>\n",
        "</center>\n",
        "<br><br>"
      ],
      "id": "f8df741e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44137430"
      },
      "source": [
        "## Regressão com Redes Neurais\n",
        "\n",
        "Projeto em: [https://github.com/anisiobfilho/regression_neuralnetworks_univasf](https://github.com/anisiobfilho/regression_neuralnetworks_univasf)"
      ],
      "id": "44137430"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e73a193e"
      },
      "source": [
        "### Importação das bases de dados"
      ],
      "id": "e73a193e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7357774a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "repo_url = 'https://raw.githubusercontent.com/anisiobfilho/regression_neuralnetworks_univasf/main'"
      ],
      "id": "7357774a",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpenujKs7ZN7"
      },
      "source": [
        "X_train = pd.read_csv(f'{repo_url}/data/preprocessed/ic_house_pred_train_X.csv')\n",
        "y_train = pd.read_csv(f'{repo_url}/data/preprocessed/ic_house_pred_train_y.csv')\n",
        "y_train_log = pd.read_csv(f'{repo_url}/data/preprocessed/ic_house_pred_train_y_log.csv')\n",
        "\n",
        "X_test = pd.read_csv(f'{repo_url}/data/preprocessed/ic_house_pred_test_X.csv')\n",
        "y_test = pd.read_csv(f'{repo_url}/data/preprocessed/ic_house_pred_test_y.csv')\n",
        "y_test_log = pd.read_csv(f'{repo_url}/data/preprocessed/ic_house_pred_test_y_log.csv')"
      ],
      "id": "zpenujKs7ZN7",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyQC3k4a9ME5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "411338cc-7d32-4d63-d8c7-009986d5e8d1"
      },
      "source": [
        "X_train.sample(3)"
      ],
      "id": "PyQC3k4a9ME5",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>MSZoning_FV</th>\n",
              "      <th>MSZoning_RH</th>\n",
              "      <th>MSZoning_RL</th>\n",
              "      <th>MSZoning_RM</th>\n",
              "      <th>...</th>\n",
              "      <th>GarageQual_Gd</th>\n",
              "      <th>GarageQual_Po</th>\n",
              "      <th>GarageQual_TA</th>\n",
              "      <th>GarageQual_ausente</th>\n",
              "      <th>GarageCond_Fa</th>\n",
              "      <th>GarageCond_Gd</th>\n",
              "      <th>GarageCond_Po</th>\n",
              "      <th>GarageCond_TA</th>\n",
              "      <th>GarageCond_ausente</th>\n",
              "      <th>PavedDrive_P</th>\n",
              "      <th>PavedDrive_Y</th>\n",
              "      <th>PoolQC_Fa</th>\n",
              "      <th>PoolQC_Gd</th>\n",
              "      <th>PoolQC_ausente</th>\n",
              "      <th>Fence_GdWo</th>\n",
              "      <th>Fence_MnPrv</th>\n",
              "      <th>Fence_MnWw</th>\n",
              "      <th>Fence_ausente</th>\n",
              "      <th>MiscFeature_Othr</th>\n",
              "      <th>MiscFeature_Shed</th>\n",
              "      <th>MiscFeature_TenC</th>\n",
              "      <th>MiscFeature_ausente</th>\n",
              "      <th>SaleType_CWD</th>\n",
              "      <th>SaleType_Con</th>\n",
              "      <th>SaleType_ConLD</th>\n",
              "      <th>SaleType_ConLI</th>\n",
              "      <th>SaleType_ConLw</th>\n",
              "      <th>SaleType_New</th>\n",
              "      <th>SaleType_Oth</th>\n",
              "      <th>SaleType_WD</th>\n",
              "      <th>SaleCondition_AdjLand</th>\n",
              "      <th>SaleCondition_Alloca</th>\n",
              "      <th>SaleCondition_Family</th>\n",
              "      <th>SaleCondition_Normal</th>\n",
              "      <th>SaleCondition_Partial</th>\n",
              "      <th>Condition2_PosA</th>\n",
              "      <th>Condition2_RRNn</th>\n",
              "      <th>Electrical_Mix</th>\n",
              "      <th>Exterior1st_ImStucc</th>\n",
              "      <th>RoofMatl_Membran</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.270548</td>\n",
              "      <td>0.052593</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.039334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.329195</td>\n",
              "      <td>0.162193</td>\n",
              "      <td>0.150757</td>\n",
              "      <td>0.462954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.303881</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.945455</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.478138</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.248629</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.205479</td>\n",
              "      <td>0.066807</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.586957</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.106839</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.300086</td>\n",
              "      <td>0.213421</td>\n",
              "      <td>0.222579</td>\n",
              "      <td>0.476029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.367935</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.481818</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.470381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038391</td>\n",
              "      <td>0.206522</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.188356</td>\n",
              "      <td>0.041328</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.116230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128425</td>\n",
              "      <td>0.156465</td>\n",
              "      <td>0.142726</td>\n",
              "      <td>0.546247</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.329691</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.945455</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.435825</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.082267</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 261 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     MSSubClass  LotFrontage  ...  Exterior1st_ImStucc  RoofMatl_Membran\n",
              "9      0.235294     0.270548  ...                  0.0               0.0\n",
              "446    0.176471     0.205479  ...                  0.0               0.0\n",
              "58     0.235294     0.188356  ...                  0.0               0.0\n",
              "\n",
              "[3 rows x 261 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfC37gUpTgKY"
      },
      "source": [
        "# Converte em aray numpy a variável alvo\n",
        "y_train = y_train.SalePrice.to_numpy()\n",
        "y_train_log = y_train_log.SalePrice.to_numpy()\n",
        "\n",
        "y_test = y_test.SalePrice.to_numpy()\n",
        "y_test_log = y_test_log.SalePrice.to_numpy()"
      ],
      "id": "gfC37gUpTgKY",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLLvkrQr-u1R"
      },
      "source": [
        "### Treinamento dos modelos"
      ],
      "id": "SLLvkrQr-u1R"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr9NgYuZFzv4"
      },
      "source": [
        "from keras.models  import Sequential\n",
        "from keras.layers import InputLayer, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_model(features, hidden, learning_rate):\n",
        "    input_neuron, hidden_neuron, output_neuron = features, hidden, 1\n",
        "\n",
        "    model = Sequential([     \n",
        "        InputLayer(input_neuron),\n",
        "        Dense(hidden_neuron, activation=\"relu\"),\n",
        "        Dense(output_neuron, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    print(f'Learning Rate = {learning_rate}\\nNeurônios na camada escondida = {hidden}')\n",
        "    print(model.summary(),'\\n\\n')\n",
        "\n",
        "    opt = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=opt, loss=\"mse\")\n",
        "\n",
        "    return model"
      ],
      "id": "zr9NgYuZFzv4",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7iTrl0IeJqY"
      },
      "source": [
        "#### Estabelecimento de parâmetros variáveis"
      ],
      "id": "w7iTrl0IeJqY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcFsrOabeI23",
        "outputId": "4f1f4bfa-0cd6-402e-c428-cd4e3d69bde1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hidden_layer_sizes = [int(X_train.shape[-1]**(1/4)), int(X_train.shape[-1]**(1/2)), 100]\n",
        "learning_rates = [0.01, 0.4, 0.1]\n",
        "\n",
        "combined_parameters = [ \n",
        "    {'lr': learning_rate, 'hidden_neurons': hidden} \\\n",
        "        for hidden in hidden_layer_sizes for learning_rate in learning_rates\n",
        "]\n",
        "combined_parameters"
      ],
      "id": "FcFsrOabeI23",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'hidden_neurons': 4, 'lr': 0.01},\n",
              " {'hidden_neurons': 4, 'lr': 0.4},\n",
              " {'hidden_neurons': 4, 'lr': 0.1},\n",
              " {'hidden_neurons': 16, 'lr': 0.01},\n",
              " {'hidden_neurons': 16, 'lr': 0.4},\n",
              " {'hidden_neurons': 16, 'lr': 0.1},\n",
              " {'hidden_neurons': 100, 'lr': 0.01},\n",
              " {'hidden_neurons': 100, 'lr': 0.4},\n",
              " {'hidden_neurons': 100, 'lr': 0.1}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdDizR4r-3-k"
      },
      "source": [
        "#### Com variável alvo sem transformação"
      ],
      "id": "CdDizR4r-3-k"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYEY86Oh-oq4",
        "outputId": "505c405a-c3b1-4aa4-87d5-d995491fbdf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "models = {\n",
        "  (item['lr'], item['hidden_neurons']): create_model(X_train.shape[-1], item['hidden_neurons'], item['lr']) \\\n",
        "      for item in combined_parameters\n",
        "}"
      ],
      "id": "LYEY86Oh-oq4",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate = 0.01\n",
            "Neurônios na camada escondida = 4\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 4)                 1048      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 1,053\n",
            "Trainable params: 1,053\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None \n",
            "\n",
            "\n",
            "Learning Rate = 0.4\n",
            "Neurônios na camada escondida = 4\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 4)                 1048      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 1,053\n",
            "Trainable params: 1,053\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None \n",
            "\n",
            "\n",
            "Learning Rate = 0.1\n",
            "Neurônios na camada escondida = 4\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 4)                 1048      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 1,053\n",
            "Trainable params: 1,053\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None \n",
            "\n",
            "\n",
            "Learning Rate = 0.01\n",
            "Neurônios na camada escondida = 16\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 16)                4192      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 4,209\n",
            "Trainable params: 4,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None \n",
            "\n",
            "\n",
            "Learning Rate = 0.4\n",
            "Neurônios na camada escondida = 16\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 16)                4192      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 4,209\n",
            "Trainable params: 4,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None \n",
            "\n",
            "\n",
            "Learning Rate = 0.1\n",
            "Neurônios na camada escondida = 16\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 16)                4192      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 4,209\n",
            "Trainable params: 4,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None \n",
            "\n",
            "\n",
            "Learning Rate = 0.01\n",
            "Neurônios na camada escondida = 100\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 100)               26200     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 26,301\n",
            "Trainable params: 26,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None \n",
            "\n",
            "\n",
            "Learning Rate = 0.4\n",
            "Neurônios na camada escondida = 100\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 100)               26200     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 26,301\n",
            "Trainable params: 26,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None \n",
            "\n",
            "\n",
            "Learning Rate = 0.1\n",
            "Neurônios na camada escondida = 100\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 100)               26200     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 26,301\n",
            "Trainable params: 26,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFHW_QBCAd7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "172a4352-f9e4-49b4-e789-ea73ef94f194"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 200\n",
        "Log = {}\n",
        "\n",
        "for pair in models.keys():\n",
        "    print(f'Treinando com:\\nLearning Rate = {pair[0]}\\nNeurônios na camada escondida = {pair[1]}\\n')\n",
        "    Log[pair] = models[pair].fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n",
        "    print('\\n\\n')"
      ],
      "id": "DFHW_QBCAd7S",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando com:\n",
            "Learning Rate = 0.01\n",
            "Neurônios na camada escondida = 4\n",
            "\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892544000.0000\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892494848.0000\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892494848.0000\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "\n",
            "\n",
            "\n",
            "Treinando com:\n",
            "Learning Rate = 0.4\n",
            "Neurônios na camada escondida = 4\n",
            "\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892494848.0000\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "\n",
            "\n",
            "\n",
            "Treinando com:\n",
            "Learning Rate = 0.1\n",
            "Neurônios na camada escondida = 4\n",
            "\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "\n",
            "\n",
            "\n",
            "Treinando com:\n",
            "Learning Rate = 0.01\n",
            "Neurônios na camada escondida = 16\n",
            "\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892507136.0000\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "\n",
            "\n",
            "\n",
            "Treinando com:\n",
            "Learning Rate = 0.4\n",
            "Neurônios na camada escondida = 16\n",
            "\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892498944.0000\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892511232.0000\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 38892503040.0000\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "\n",
            "\n",
            "\n",
            "Treinando com:\n",
            "Learning Rate = 0.01\n",
            "Neurônios na camada escondida = 100\n",
            "\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "\n",
            "\n",
            "\n",
            "Treinando com:\n",
            "Learning Rate = 0.4\n",
            "Neurônios na camada escondida = 100\n",
            "\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 1s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892494848.0000\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892494848.0000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892494848.0000\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892494848.0000\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892494848.0000\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "\n",
            "\n",
            "\n",
            "Treinando com:\n",
            "Learning Rate = 0.1\n",
            "Neurônios na camada escondida = 100\n",
            "\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892515328.0000\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892494848.0000\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 38892507136.0000\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 38892498944.0000\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892498944.0000\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892511232.0000\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892507136.0000\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892511232.0000\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 38892503040.0000\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892503040.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892507136.0000\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 38892498944.0000\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPiRxplQAryK"
      },
      "source": [
        "### Medidas de Desempenho\n",
        "Para este projeto de regressão, utilizou-se:\n",
        "- **r2_score**(y_test, y_pred)\n",
        "\n",
        "- **median_absolute_error**(y_test, y_pred)\n",
        "\n",
        "- **Gráfico de Dispersão**"
      ],
      "id": "VPiRxplQAryK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-70aJRb8Bqmc"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def plot_target_metricts(mlp, X_test, y_test, transformed=False):\n",
        "  y_pred = np.expm1(mlp.predict(X_test)) if transformed else mlp.predict(X_test)\n",
        "  y_pred = y_pred.flatten()\n",
        "  print(np.random.choice(y_pred, size=10, replace=False))\n",
        "\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "  mae = median_absolute_error(y_test, y_pred)\n",
        "\n",
        "  # Plot results\n",
        "  ax = plt.axes()\n",
        "\n",
        "  ax.scatter(y_test, y_pred)\n",
        "  ax.plot([0, 80000], [-10000, 80000], '--k')\n",
        "  ax.set_ylabel('Target predicted')\n",
        "  ax.set_xlabel('True Target')\n",
        "  ax.set_title('Sem transformação logarítmica do alvo')\n",
        "  ax.text(10000, 70000, r'$R^2$=%.2f, MAE=%.2f' % (\n",
        "      r2, mae))\n",
        "  ax.set_xlim([0, 80000])\n",
        "  ax.set_ylim([-10000, 80000])"
      ],
      "id": "-70aJRb8Bqmc",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oafHmSBBKe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "outputId": "afdae237-d1ef-4b2f-e34e-525739376fe7"
      },
      "source": [
        "for pair in models.keys():\n",
        "    plot_target_metricts(models[pair], X_test, y_test)"
      ],
      "id": "7oafHmSBBKe3",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJEkllATLIz5"
      },
      "source": [
        "#### Comparação da distribuição com e sem a transformação logarítmica"
      ],
      "id": "tJEkllATLIz5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpaW6IQZLGm8",
        "outputId": "d7707f6a-8e87-42f4-f6db-72ce47056005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "f, (ax0, ax1) = plt.subplots(1, 2)\n",
        "\n",
        "ax0.hist(y_train, bins=100, density=True)\n",
        "ax0.set_xlim([0, max(y_train)])\n",
        "ax0.set_ylabel('Probability')\n",
        "ax0.set_xlabel('Target')\n",
        "ax0.set_title('Target distribution')\n",
        "\n",
        "ax1.hist(y_train_log, bins=100, density=True)\n",
        "ax1.set_ylabel('Probability')\n",
        "ax1.set_xlabel('Target')\n",
        "ax1.set_title('Transformed target distribution')\n",
        "\n",
        "f.tight_layout(rect=[0.05, 0.05, 0.95, 0.95])\n"
      ],
      "id": "YpaW6IQZLGm8",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko8fkvjV_SJ3"
      },
      "source": [
        "#### Treinamento com variável alvo com transformação logarítmica"
      ],
      "id": "Ko8fkvjV_SJ3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NyKn9jJTJgN",
        "outputId": "c94a5cf4-5c97-498b-b9ee-60edec1ea965",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for pair in models.keys():\n",
        "    print(f'Treinando com:\\nLearning Rate = {pair[0]}\\nNeurônios na camada escondida = {pair[1]}')\n",
        "    Log[pair] = models[pair].fit(X_train, y_train_log, batch_size=batch_size, epochs=epochs)"
      ],
      "id": "5NyKn9jJTJgN",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando com:\n",
            "Learning Rate = 0.01\n",
            "Neurônios na camada escondida = 4\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Treinando com:\n",
            "Learning Rate = 0.4\n",
            "Neurônios na camada escondida = 4\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Treinando com:\n",
            "Learning Rate = 0.1\n",
            "Neurônios na camada escondida = 4\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Treinando com:\n",
            "Learning Rate = 0.01\n",
            "Neurônios na camada escondida = 16\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Treinando com:\n",
            "Learning Rate = 0.4\n",
            "Neurônios na camada escondida = 16\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Treinando com:\n",
            "Learning Rate = 0.1\n",
            "Neurônios na camada escondida = 16\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 121.7915\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Treinando com:\n",
            "Learning Rate = 0.01\n",
            "Neurônios na camada escondida = 100\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Treinando com:\n",
            "Learning Rate = 0.4\n",
            "Neurônios na camada escondida = 100\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Treinando com:\n",
            "Learning Rate = 0.1\n",
            "Neurônios na camada escondida = 100\n",
            "Epoch 1/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 121.7915\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 121.7915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUoxIdqQVOcp",
        "outputId": "073b5ba6-f740-42a1-a1dd-441f049ba002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893
        }
      },
      "source": [
        "for pair in models.keys():\n",
        "    plot_target_metricts(models[pair], X_test, y_test_log, transformed=True)"
      ],
      "id": "kUoxIdqQVOcp",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817\n",
            " 1.7182817 1.7182817 1.7182817]\n",
            "[1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817\n",
            " 1.7182817 1.7182817 1.7182817]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817\n",
            " 1.7182817 1.7182817 1.7182817]\n",
            "[1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817\n",
            " 1.7182817 1.7182817 1.7182817]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817\n",
            " 1.7182817 1.7182817 1.7182817]\n",
            "[1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817\n",
            " 1.7182817 1.7182817 1.7182817]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817\n",
            " 1.7182817 1.7182817 1.7182817]\n",
            "[1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817\n",
            " 1.7182817 1.7182817 1.7182817]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817 1.7182817\n",
            " 1.7182817 1.7182817 1.7182817]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}